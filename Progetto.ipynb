{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matibag1714977/LabiagiProject/blob/main/Progetto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1kS8KmI4OEV"
      },
      "source": [
        "# **Progetto-Scene Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuLIneGUQ0WZ"
      },
      "source": [
        "#Import vari"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "j3iBMU-v4Tl0"
      },
      "outputs": [],
      "source": [
        "import numpy as np      #to perform mathematical operations on arrays and matrices\n",
        "import matplotlib.pyplot as plt  #to visualize images and plot graphs\n",
        "\n",
        "#provides algoithms and tools for data analysis and modeling(classification,regression,clustering)\n",
        "from sklearn.model_selection import train_test_split        \n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# It provides various tools and functions for image and video processing, including image filtering, feature detection, and object tracking.\n",
        "import cv2\n",
        "import imghdr\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "375Lbwv8b64g"
      },
      "source": [
        "#Import dataset Prova"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iMJbpe2i4UoR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e739de86-4311-424b-9944-cd3e2ea3ec96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "#folder_id = '1pFM_HpOjh0qbAadk0-1Fz89mwLHrnQHB?usp=share_link'\n",
        "folder_id ='1uN5c1p7GkKE9xqQ3DyFbFWfRJQCTod-E?usp=share_link'\n",
        "data_path = '/content/gdrive/MyDrive/Dataset/input_data2'\n",
        "\n",
        "\n",
        "# mount the folder\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con SUN397"
      ],
      "metadata": {
        "id": "kELggI-KO4g0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = '/content/gdrive/MyDrive/Dataset/SUN397'\n",
        "classess = os.listdir(dataset_dir)\n",
        "print(len(classess))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGWEwXKeJAPS",
        "outputId": "9ec6a080-3017-4657-c1f0-834a001bb5a0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dividere tramite Pytorch"
      ],
      "metadata": {
        "id": "IYUmCGVNdu7q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "100 ogni classe"
      ],
      "metadata": {
        "id": "mfK0mI7v3pOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Subset\n",
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "\n",
        "# Definire la trasformazione delle immagini\n",
        "transform = transforms.Compose(\n",
        "    [transforms.Resize((224, 224)),transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# Definire il percorso della cartella contenente le immagini selezionate\n",
        "dataset_path = '/content/gdrive/MyDrive/Dataset/SUN397'\n",
        "\n",
        "# Creare un dataset PyTorch dalla cartella delle immagini selezionate\n",
        "dataset = ImageFolder(dataset_path, transform=transform)\n",
        "classes276 = dataset.classes\n",
        "# Creare un elenco di indici di campioni per ogni classe\n",
        "class_indices = dataset.class_to_idx\n",
        "indices = []\n",
        "for c in class_indices.values():\n",
        "    class_samples = [i for i, (_, label) in enumerate(dataset.samples) if label == c]\n",
        "    indices += random.sample(class_samples, 100)\n",
        "\n",
        "# Creare un Subset di PyTorch dataset contenente solo gli indici selezionati\n",
        "subset = Subset(dataset, indices)\n",
        "b_size=10\n",
        "\n",
        "# Dividere il Subset in train, validation e test set utilizzando random_split\n",
        "train_ratio = 0.8\n",
        "val_ratio = 0.1\n",
        "test_ratio = 0.1\n",
        "train_data = int(len(subset) * train_ratio)\n",
        "val_data = int(len(subset) * val_ratio)\n",
        "test_data = len(subset) - train_data - val_data\n",
        "train_set, val_set, test_set = data.random_split(subset, [train_data, val_data, test_data])\n",
        "\n",
        "train_loader=data.DataLoader(train_set,batch_size=b_size, shuffle=True, num_workers=2)\n",
        "validation_loader=data.DataLoader(val_set,batch_size=b_size, shuffle=False,  num_workers=2)\n",
        "test_loader=data.DataLoader(test_set,batch_size=b_size,shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "# Stampa delle dimensioni di ogni set\n",
        "print(f\"Numero di campioni di training: {len(train_set)}\")\n",
        "print(f\"Numero di campioni di validation: {len(val_set)}\")\n",
        "print(f\"Numero di campioni di test: {len(test_set)}\")\n",
        "print(classes276)"
      ],
      "metadata": {
        "id": "UH_0e3Sn2eRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tutto"
      ],
      "metadata": {
        "id": "T-jwfIfz3tmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "\n",
        "# Definisci la trasformazione delle immagini\n",
        "transform = transforms.Compose(\n",
        "    [transforms.Resize((224, 224)),transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "input_path='/content/gdrive/MyDrive/Dataset/SUN397'\n",
        "# Trasforma il dataset\n",
        "dataset = datasets.ImageFolder(input_path, transform=transform)\n",
        "\n",
        "#print(dataset)\n",
        "\n",
        "# Definisci le proporzioni di training, validation e test set\n",
        "train_ratio = 0.80\n",
        "val_ratio = 0.10\n",
        "test_ratio = 0.10\n",
        "\n",
        "b_size=27\n",
        "\n",
        "# Calcola le lunghezze dei subset\n",
        "train_size = int(train_ratio * len(dataset))\n",
        "val_size = int(val_ratio * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "# Dividi il dataset in training, validation e test set\n",
        "train_data, test_data, val_data = data.random_split(dataset, [train_size, test_size, val_size])\n",
        "\n",
        "train_loader=data.DataLoader(train_data,batch_size=b_size, shuffle=True, num_workers=2)\n",
        "validation_loader=data.DataLoader(val_data,batch_size=b_size, shuffle=True,  num_workers=2)\n",
        "test_loader=data.DataLoader(test_data,batch_size=b_size,shuffle=False, num_workers=2)\n",
        "\n",
        "print(len(train_data))\n",
        "print(len(val_data))\n",
        "print(len(test_data))\n",
        "\n",
        "#classes = ('airport_terminal', 'beach', 'bridge', 'forest',\n",
        "  #         'mountain', 'playground', 'river', 'skyscraper', 'street', 'temple')\n",
        "#classes = ('airport_terminal', 'beach', 'bridge','fire_station', 'forest','formal_garden','fountain','ice_skating','iceberg','lake','market',\n",
        "   #        'mountain', 'playground', 'river','rock_arch','ruin', 'skyscraper', 'street', 'temple','tennis_court')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "exkgfvDEduUD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dfe7d92-decb-45cc-e20f-3f745c8d70f1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63512\n",
            "7939\n",
            "7939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Carico resnet50"
      ],
      "metadata": {
        "id": "gE18143K25BF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "\n",
        "# Load ResNet50 model\n",
        "resnet50 = models.resnet50(weights=None)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IRM685tZ9LUT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prova uso gpu"
      ],
      "metadata": {
        "id": "xGOa5GxR_cRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "  print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"Using CPU\")\n",
        "print(device)\n",
        "\n",
        "# Resnet che corre su device\n",
        "resnet50.to(device)"
      ],
      "metadata": {
        "id": "goUrzNLA2uij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss e optimizer"
      ],
      "metadata": {
        "id": "slTrTI8E1yrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(resnet50.parameters(), lr=0.001, momentum=0.9)\n",
        "#optimizer = optim.Adam(resnet50.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "iFPd03VD-fSa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "XvpIRJcCH_ac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inizializzo le liste per raccogliere dati"
      ],
      "metadata": {
        "id": "9sO0aofz8Pbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_values = []  # lista vuota per raccogliere i valori della loss function\n",
        "val_loss_values = []"
      ],
      "metadata": {
        "id": "5zxi-Ir88OdH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carico dati"
      ],
      "metadata": {
        "id": "tbPFJDqRHjL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_values = np.load('/content/gdrive/MyDrive/Dataset/Test3/loss_Adam_001.npy').tolist()\n",
        "val_loss_values=np.load('/content/gdrive/MyDrive/Dataset/Test3/val_Adam_001.npy').tolist()"
      ],
      "metadata": {
        "id": "d3D7IqrrHjg6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definisco validation"
      ],
      "metadata": {
        "id": "U47fJ4LW-sF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, criterion, validation_loader):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for data in validation_loader:\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "    return val_loss / len(validation_loader)"
      ],
      "metadata": {
        "id": "3HJpwCv--rfT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "CVwmWQy5-wht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=10\n",
        "PATH = '/content/gdrive/MyDrive/Dataset/Test4/001.pth'\n",
        "\n",
        "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        #inputs, labels = data\n",
        "\n",
        "        #mandare inputs e a ogni passo alla gpu\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = resnet50(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # statistica\n",
        "        running_loss += loss.item()\n",
        "        if i % 200== 199: # ogni 200 batch da b_size immagini\n",
        "            # aggiungi il valore della loss alla lista\n",
        "            loss_values.append(running_loss / 200)\n",
        "            val_loss = validate(resnet50, criterion, validation_loader)\n",
        "            val_loss_values.append(val_loss)\n",
        "            print(f'[{epoch + 1},{i + 1:4d}] loss: {running_loss / 200:.3f} val_loss:{val_loss:.3f}')\n",
        "            running_loss = 0.0\n",
        "            \n",
        "            torch.save(resnet50.state_dict(), PATH)   \n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "4ZcAPUB3adBq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee1a8ecb-484c-4ae1-aeff-b7e05800fcba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 200] loss: 6.444 val_loss:6.648\n",
            "[1, 400] loss: 6.059 val_loss:6.065\n",
            "[1, 600] loss: 5.950 val_loss:5.883\n",
            "[1, 800] loss: 5.840 val_loss:5.720\n",
            "[1,1000] loss: 5.725 val_loss:5.649\n",
            "[1,1200] loss: 5.609 val_loss:5.585\n",
            "[1,1400] loss: 5.536 val_loss:5.465\n",
            "[1,1600] loss: 5.465 val_loss:5.402\n",
            "[1,1800] loss: 5.415 val_loss:5.362\n",
            "[1,2000] loss: 5.303 val_loss:5.252\n",
            "[1,2200] loss: 5.292 val_loss:5.214\n",
            "[2, 200] loss: 5.169 val_loss:5.196\n",
            "[2, 400] loss: 5.166 val_loss:5.170\n",
            "[2, 600] loss: 5.072 val_loss:5.047\n",
            "[2, 800] loss: 5.012 val_loss:5.003\n",
            "[2,1000] loss: 4.978 val_loss:4.973\n",
            "[2,1200] loss: 4.943 val_loss:5.070\n",
            "[2,1400] loss: 4.932 val_loss:4.905\n",
            "[2,1600] loss: 4.833 val_loss:4.876\n",
            "[2,1800] loss: 4.806 val_loss:4.865\n",
            "[2,2000] loss: 4.835 val_loss:4.756\n",
            "[2,2200] loss: 4.762 val_loss:4.771\n",
            "[3, 200] loss: 4.649 val_loss:4.700\n",
            "[3, 400] loss: 4.665 val_loss:4.733\n",
            "[3, 600] loss: 4.672 val_loss:4.696\n",
            "[3, 800] loss: 4.595 val_loss:4.732\n",
            "[3,1000] loss: 4.591 val_loss:4.728\n",
            "[3,1200] loss: 4.562 val_loss:4.571\n",
            "[3,1400] loss: 4.533 val_loss:4.580\n",
            "[3,1600] loss: 4.526 val_loss:4.571\n",
            "[3,1800] loss: 4.480 val_loss:4.507\n",
            "[3,2000] loss: 4.444 val_loss:4.496\n",
            "[3,2200] loss: 4.482 val_loss:4.464\n",
            "[4, 200] loss: 4.317 val_loss:4.451\n",
            "[4, 400] loss: 4.368 val_loss:4.506\n",
            "[4, 600] loss: 4.313 val_loss:4.357\n",
            "[4, 800] loss: 4.304 val_loss:4.380\n",
            "[4,1000] loss: 4.303 val_loss:4.296\n",
            "[4,1200] loss: 4.324 val_loss:4.319\n",
            "[4,1400] loss: 4.275 val_loss:4.408\n",
            "[4,1600] loss: 4.237 val_loss:4.304\n",
            "[4,1800] loss: 4.240 val_loss:4.340\n",
            "[4,2000] loss: 4.235 val_loss:4.354\n",
            "[4,2200] loss: 4.207 val_loss:4.372\n",
            "[5, 200] loss: 4.070 val_loss:4.278\n",
            "[5, 400] loss: 4.023 val_loss:4.183\n",
            "[5, 600] loss: 4.112 val_loss:4.214\n",
            "[5, 800] loss: 4.040 val_loss:4.242\n",
            "[5,1000] loss: 4.110 val_loss:4.194\n",
            "[5,1200] loss: 4.110 val_loss:4.161\n",
            "[5,1400] loss: 4.056 val_loss:4.160\n",
            "[5,1600] loss: 4.014 val_loss:4.093\n",
            "[5,1800] loss: 4.009 val_loss:4.134\n",
            "[5,2000] loss: 3.991 val_loss:4.106\n",
            "[5,2200] loss: 3.981 val_loss:4.066\n",
            "[6, 200] loss: 3.836 val_loss:4.068\n",
            "[6, 400] loss: 3.902 val_loss:4.071\n",
            "[6, 600] loss: 3.838 val_loss:4.081\n",
            "[6, 800] loss: 3.823 val_loss:4.065\n",
            "[6,1000] loss: 3.846 val_loss:4.052\n",
            "[6,1200] loss: 3.870 val_loss:4.008\n",
            "[6,1400] loss: 3.840 val_loss:3.996\n",
            "[6,1600] loss: 3.895 val_loss:4.010\n",
            "[6,1800] loss: 3.829 val_loss:3.983\n",
            "[6,2000] loss: 3.818 val_loss:4.014\n",
            "[6,2200] loss: 3.793 val_loss:3.902\n",
            "[7, 200] loss: 3.686 val_loss:3.958\n",
            "[7, 400] loss: 3.621 val_loss:3.914\n",
            "[7, 600] loss: 3.634 val_loss:3.976\n",
            "[7, 800] loss: 3.626 val_loss:3.834\n",
            "[7,1000] loss: 3.660 val_loss:4.044\n",
            "[7,1200] loss: 3.651 val_loss:3.895\n",
            "[7,1400] loss: 3.650 val_loss:3.963\n",
            "[7,1600] loss: 3.602 val_loss:3.889\n",
            "[7,1800] loss: 3.679 val_loss:3.915\n",
            "[7,2000] loss: 3.698 val_loss:3.781\n",
            "[7,2200] loss: 3.658 val_loss:3.814\n",
            "[8, 200] loss: 3.449 val_loss:3.798\n",
            "[8, 400] loss: 3.458 val_loss:3.826\n",
            "[8, 600] loss: 3.494 val_loss:3.756\n",
            "[8, 800] loss: 3.513 val_loss:3.797\n",
            "[8,1000] loss: 3.429 val_loss:3.734\n",
            "[8,1200] loss: 3.452 val_loss:3.892\n",
            "[8,1400] loss: 3.459 val_loss:3.778\n",
            "[8,1600] loss: 3.477 val_loss:3.695\n",
            "[8,1800] loss: 3.462 val_loss:3.810\n",
            "[8,2000] loss: 3.407 val_loss:3.715\n",
            "[8,2200] loss: 3.490 val_loss:3.712\n",
            "[9, 200] loss: 3.192 val_loss:3.702\n",
            "[9, 400] loss: 3.277 val_loss:3.712\n",
            "[9, 600] loss: 3.331 val_loss:3.788\n",
            "[9, 800] loss: 3.265 val_loss:3.789\n",
            "[9,1000] loss: 3.249 val_loss:3.664\n",
            "[9,1200] loss: 3.346 val_loss:3.665\n",
            "[9,1400] loss: 3.311 val_loss:3.829\n",
            "[9,1600] loss: 3.324 val_loss:3.699\n",
            "[9,1800] loss: 3.300 val_loss:3.609\n",
            "[9,2000] loss: 3.292 val_loss:3.648\n",
            "[9,2200] loss: 3.265 val_loss:3.705\n",
            "[10, 200] loss: 3.050 val_loss:3.707\n",
            "[10, 400] loss: 3.073 val_loss:3.634\n",
            "[10, 600] loss: 3.072 val_loss:3.684\n",
            "[10, 800] loss: 3.181 val_loss:3.667\n",
            "[10,1000] loss: 3.091 val_loss:3.643\n",
            "[10,1200] loss: 3.086 val_loss:3.697\n",
            "[10,1400] loss: 3.090 val_loss:3.748\n",
            "[10,1600] loss: 3.078 val_loss:3.583\n",
            "[10,1800] loss: 3.113 val_loss:3.590\n",
            "[10,2000] loss: 3.078 val_loss:3.548\n",
            "[10,2200] loss: 3.105 val_loss:3.505\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training con K-Fold-Crossvalidation"
      ],
      "metadata": {
        "id": "Ne4tFKFagGvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import os\n",
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "# Definisci la trasformazione delle immagini\n",
        "transform = transforms.Compose(\n",
        "    [transforms.Resize((224, 224)),transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "input_path='/content/gdrive/MyDrive/Dataset/SUN397'\n",
        "# Trasforma il dataset\n",
        "dataset = datasets.ImageFolder(input_path, transform=transform)\n",
        "\n",
        "# Definisci le proporzioni di training, validation e test set\n",
        "train_ratio = 0.90\n",
        "test_ratio = 0.10\n",
        "\n",
        "b_size=10\n",
        "\n",
        "# Calcola le lunghezze dei subset\n",
        "train_size = int(train_ratio * len(dataset))\n",
        "test_size = len(dataset) - train_size \n",
        "\n",
        "# Dividi il dataset in training, validation e test set\n",
        "train_dataset, test_data= data.random_split(dataset, [train_size, test_size])"
      ],
      "metadata": {
        "id": "zcpOdD-LjN48"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definisci il numero di fold\n",
        "k = 5\n",
        "kf = KFold(n_splits=k)\n",
        "num_epochs=2\n",
        "\n",
        "\n",
        "# Loop over folds\n",
        "for fold, (train_indices, val_indices) in enumerate(kf.split(train_dataset)):\n",
        "\n",
        "    # Definisci i dataloaders per il train e la validation per il fold corrente\n",
        "    train_sampler = SubsetRandomSampler(train_indices)\n",
        "    val_sampler = SubsetRandomSampler(val_indices)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=b_size, sampler=train_sampler)\n",
        "    validation_loader = torch.utils.data.DataLoader(train_dataset, batch_size=b_size, sampler=val_sampler)\n",
        "\n",
        "    # Inizializza il modello e l'ottimizzatore per ogni fold\n",
        "    resnet50 = models.resnet50(weights=None)\n",
        "    resnet50.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(resnet50.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    # Loop over epochs per il fold corrente\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        resnet50.train() # setta il modello in modalit√† training\n",
        "\n",
        "        # Loop over batches per il fold corrente\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = resnet50(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Calcola la perdita sul training set per il fold corrente\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        loss_values.append(train_loss)\n",
        "\n",
        "        # Calcola la perdita sulla validation set per il fold corrente\n",
        "        val_loss = validate(resnet50, criterion, validation_loader)\n",
        "        val_loss_values.append(val_loss)\n",
        "\n",
        "        # Stampa la perdita corrente\n",
        "        print(f\"Fold {fold+1}/{k}, Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "    # Salva i pesi del modello per il fold corrente\n",
        "    path = \"/content/drive/MyDrive/Test4/fold\" + str(fold+1) + \".pth\"\n",
        "    torch.save(resnet50.state_dict(), path)\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "id": "OEwpJ3mrgGdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Salvo dati"
      ],
      "metadata": {
        "id": "Cjr4X6WDDago"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/content/gdrive/MyDrive/Dataset/Test4/loss_SGD_.npy', loss_values)\n",
        "np.save('/content/gdrive/MyDrive/Dataset/Test4/val_SGD_.npy', val_loss_values)"
      ],
      "metadata": {
        "id": "bpMN_tGxDZYn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stampo loss function"
      ],
      "metadata": {
        "id": "utrwg-_J0ndl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creo grafico lineare\n",
        "plt.plot(loss_values)\n",
        "plt.plot(val_loss_values)\n",
        "\n",
        "# titolo e assi\n",
        "plt.title('Loss/Val Function')\n",
        "plt.xlabel('200Batch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.legend(['loss','val_loss'],loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "UgvH06vG0nzQ",
        "outputId": "eaf57f73-4839-4b0a-b60a-e7dcb074aa44"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Salvo il modello dopo il training"
      ],
      "metadata": {
        "id": "-Yxolou9U1qW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/gdrive/MyDrive/Dataset/Test4/001.pth'\n",
        "torch.save(resnet50.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "xZ2k8dnJUZA5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carico modello salvato precedentemente"
      ],
      "metadata": {
        "id": "3aVgGiqXHMLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50 = models.resnet50(weights=None)\n",
        "PATH = '/content/gdrive/MyDrive/Dataset/2_SGD_001/resnet50lr001.pth'\n",
        "# Carico i pesi salvati precedentemente\n",
        "resnet50.load_state_dict(torch.load(PATH))\n",
        "resnet50.to(device)"
      ],
      "metadata": {
        "id": "1O_wH4PFF9bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Uso modello su test"
      ],
      "metadata": {
        "id": "TBWV-sdyU87w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rBlo09ahpRF"
      },
      "outputs": [],
      "source": [
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = resnet50(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    \n",
        "accuracy = 100 * correct / total\n",
        "print('Accuracy of the model on the test images: {:.2f}%'.format(accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Classi peggiori e migliori"
      ],
      "metadata": {
        "id": "6X7mytwB0FGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in classes276}\n",
        "total_pred = {classname: 0 for classname in classes276}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = resnet50(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes276[label]] += 1\n",
        "            total_pred[classes276[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class in descending order of accuracy\n",
        "for classname, correct_count in sorted(correct_pred.items(), key=lambda x: x[1], reverse=True):\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n",
        "\n",
        "# calculate overall accuracy\n",
        "total_correct = sum(correct_pred.values())\n",
        "total = sum(total_pred.values())\n",
        "overall_accuracy = 100 * float(total_correct) / total\n",
        "print(f'\\nOverall accuracy is {overall_accuracy:.1f} %')\n"
      ],
      "metadata": {
        "id": "nw01na2R0EW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test con immagini"
      ],
      "metadata": {
        "id": "qeVSZ8V9GRW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(test_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join(f'{classes276[labels[j]]:5s}' for j in range(4)))"
      ],
      "metadata": {
        "id": "2MFuRFeHGp1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = images.to(device)\n",
        "outputs = resnet50(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
        "                              for j in range(4)))"
      ],
      "metadata": {
        "id": "kWrZND_pGaUn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "KLVi4dMe1h48",
        "Ne4tFKFagGvA"
      ],
      "authorship_tag": "ABX9TyN9MtJlIpWJ1OqQBvz5OG2p",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}